{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Single Inference\n",
    "\n",
    "> Warning: The major caveat here is that this really should be run via script and **NOT** in a notebook. That being said, this is the best way to introduce the concepts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/08\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "from larcv import larcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The below instantiates the network based off the description in the prototxt and the saved pre-trained snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = caffe.Net('/workspace/plainresnet10b/sp_plainresnet10b_test.prototxt',\n",
    "                '/workspace/plainresnet10b/sp_plainresnet10b_iter_195750.caffemodel.h5',\n",
    "                caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filler_name = 'ThreadDatumFiller'\n",
    "# check if larcv IO processor does in fact exist and registered in a factory\n",
    "if not larcv.ThreadFillerFactory.exist_filler(filler_name):\n",
    "    print '\\033[93mFiller',filler_name,'does not exist...\\033[00m'\n",
    "\n",
    "# get IO instance, ThreadDatumFiller instance, from the factory\n",
    "filler = larcv.ThreadFillerFactory.get_filler(filler_name)\n",
    "\n",
    "# get # events to be processed \n",
    "num_events = filler.get_n_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# force random access to be false for an inference\n",
    "filler.set_random_access(False)\n",
    "\n",
    "# construct our own IO to fetch ROI object for physics analysis, use RED mode w/ same input files\n",
    "myio = larcv.IOManager(0,\"AnaIO\")\n",
    "for f in filler.pd().io().file_list():\n",
    "    myio.add_in_file(f)\n",
    "myio.initialize()\n",
    "print\n",
    "print '\\033[95mTotal number of events\\033[00m:',num_events\n",
    "print '\\033[95mBatch size\\033[00m:', self._batch_size\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "      event_counter = 0    # this variable denotes which TTree entry we are @ in the loop below\n",
    "        stop_counter  = 1e10 # well, unused, but one can set a break condition by configuring this parameter\n",
    "        correct_count = 0    # counter for correctly labeled events\n",
    "\n",
    "        # now continue a loop till the end of the input file (event list)\n",
    "        while 1:\n",
    "\n",
    "            # if previous result is loaded, check if we should process the current entry or not\n",
    "            if done_list and (event_counter in done_list):\n",
    "                event_counter+=1\n",
    "                continue\n",
    "\n",
    "            # force the filler to move the next event-to-read pointer to the entry of our interest\n",
    "            filler.set_next_index(event_counter)\n",
    "\n",
    "            # number of entries we expect to process in this mini-batch\n",
    "            num_entries = num_events - event_counter\n",
    "            if num_entries > self._batch_size: \n",
    "                num_entries = self._batch_size\n",
    "\n",
    "            # now run the network for a mini-batch, sleep while the thread is running\n",
    "            net.forward()\n",
    "            while filler.thread_running():\n",
    "                time.sleep(0.001)\n",
    "\n",
    "            # retrieve ROI product producer from the filler, so we can read-in ROI products through myroi \n",
    "            roi_producer = filler.producer(1)\n",
    "\n",
    "            # get a vector of integers that record TTree entry numbers processed in this mini-batch\n",
    "            entries = filler.processed_entries()\n",
    "            if entries.size() != self._batch_size:\n",
    "                print \"\\033[93mBatch counter mis-match!\\033[00m\"\n",
    "                raise Exception\n",
    "\n",
    "            # retrieve data already read-and-stored-in-memory from caffe blob\n",
    "            adcimgs = net.blobs[\"data\"].data    # this is image\n",
    "            labels  = net.blobs[\"label\"].data   # this is label\n",
    "            scores  = net.blobs[\"softmax\"].data # this is final output softmax vector\n",
    "            \n",
    "            # loop over entry of mini-batch outcome\n",
    "            for index in xrange(num_entries):\n",
    "                \n",
    "                if not entries[index] == event_counter:\n",
    "                    print '\\033[93mLogic error... inconsistency found in expected entry (%d) vs. processing entry (%d)' % (event_counter,entries[index])\n",
    "                    self.__class__._terminate = True\n",
    "                    break\n",
    "                # skip if this is alredy recorded entry\n",
    "                if done_list and (event_counter in done_list):\n",
    "                    event_counter +=1\n",
    "                    continue\n",
    "                \n",
    "                # declare csv_vals dictionary instance, and fill necessary key-value pairs.\n",
    "                # later we have an explicit check if all keys are filled.\n",
    "                # this is helpful to avoid a mistake when someone udpate later the script\n",
    "                # to include/exclude variables in CSV_VARS definition and forgot to update this\n",
    "                # portion of the code.\n",
    "                csv_vals={}\n",
    "                adcimg = adcimgs [index] # ADC raw image\n",
    "                label  = labels  [index]  # Labels\n",
    "                score  = scores  [index]  # results\n",
    "                # fill things that can be filled from caffe blob\n",
    "                csv_vals['entry'  ] = entries[index]\n",
    "                csv_vals['npx'    ] = (adcimg > 0).sum()\n",
    "                csv_vals['label'  ] = int(label)\n",
    "                csv_vals['prediction'] = score.argmax()\n",
    "                csv_vals['eminus' ] = score[0]\n",
    "                csv_vals['gamma'  ] = score[1]\n",
    "                csv_vals['muminus'] = score[2]\n",
    "                csv_vals['piminus'] = score[3]\n",
    "                csv_vals['proton' ] = score[4]\n",
    "\n",
    "                if int(label) == score.argmax():\n",
    "                    correct_count += 1\n",
    "                \n",
    "                # now get ROI data from myroi, our separate IO handle, to record physics parameters\n",
    "                myio.read_entry(entries[index])\n",
    "                event_roi = myio.get_data(1,roi_producer)\n",
    "                \n",
    "                csv_vals['nparticle']=0\n",
    "                csv_vals['ndecay']=0\n",
    "                csv_vals['energy_dep']=0.\n",
    "                # loop over ROIs\n",
    "                for roi in event_roi.ROIArray():\n",
    "                    if roi.MCSTIndex() == larcv.kINVALID_USHORT:\n",
    "                        # ROI from simb::MCTruth\n",
    "                        csv_vals['energy_start']=roi.EnergyInit()\n",
    "                        csv_vals['mass'] = larcv.ParticleMass(roi.PdgCode())\n",
    "                        px,py,pz = (roi.Px(),roi.Py(),roi.Pz())\n",
    "                        ptot = np.sqrt(np.power(px,2)+np.power(py,2)+np.power(pz,2))\n",
    "                        csv_vals['mom_start'] = ptot\n",
    "                        csv_vals['dcosx_start'] = px/ptot\n",
    "                        csv_vals['dcosy_start'] = py/ptot\n",
    "                        csv_vals['dcosz_start'] = pz/ptot\n",
    "                    else:\n",
    "                        # ROI from sim::MCShower and sim::MCTrack\n",
    "                        csv_vals['nparticle']+=1\n",
    "                        if roi.ParentTrackID() == roi.TrackID():\n",
    "                            csv_vals['energy_dep'] = roi.EnergyDeposit()\n",
    "                        elif np.abs(roi.PdgCode()) == 13 and np.abs(roi.ParentPdgCode()) == 211:\n",
    "                            csv_vals['ndecay'] += 1\n",
    "                        elif np.abs(roi.PdgCode()) == 11 and np.abs(roi.ParentPdgCode()) == 13:\n",
    "                            csv_vals['ndecay'] += 1\n",
    "                # record in csv format\n",
    "                line = ''\n",
    "                for v in CSV_VARS:\n",
    "                    try:\n",
    "                        line += '%s,' % str(csv_vals[v])\n",
    "                    except KeyError:\n",
    "                        print '\\033[93mCould not locate field\\033[00m:',v\n",
    "                        self.__class__._terminate=True\n",
    "                        break\n",
    "                line=line.rstrip(',')\n",
    "                line+='\\n'\n",
    "                fout.write(line)\n",
    "\n",
    "                # break if stop counter is met\n",
    "                event_counter += 1\n",
    "\n",
    "                # update an user which entry we are processing\n",
    "                sys.stdout.write('Processed entry %d ... accuracy @ %g    \\r' % (event_counter,float(correct_count)/event_counter))\n",
    "\n",
    "                if event_counter >= stop_counter:\n",
    "                    break\n",
    "                # break if termination is called\n",
    "                if self.__class__._terminate:\n",
    "                    break\n",
    "\n",
    "            # break if all entries are processed\n",
    "            if num_entries < self._batch_size:\n",
    "                break\n",
    "            # break if stop counter is met\n",
    "            if event_counter >= stop_counter:\n",
    "                break\n",
    "            # break if termination is called\n",
    "            if self.__class__._terminate:\n",
    "                print\n",
    "                print '\\033[93mAborting upon kernel kill signal...\\033[00m'\n",
    "                break\n",
    "        print\n",
    "        # close outputs and input io\n",
    "        fout.close()\n",
    "        myio.finalize()\n",
    "        # destroy thread filler via factory, an owner\n",
    "        larcv.ThreadFillerFactory.destroy_filler(self._filler_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
