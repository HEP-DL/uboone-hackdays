{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Single Inference\n",
    "\n",
    "> Warning: The major caveat here is that this really should be run via script and **NOT** in a notebook. That being said, this is the best way to introduce the concepts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/08\n"
     ]
    }
   ],
   "source": [
    "import matplotlib \n",
    "# This can also be ipython magic such as `matplotlib inline` or `matplotlib notebook`\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os,commands,signal,sys,tempfile\n",
    "os.environ['GLOG_minloglevel'] = '2' # set message level to warning\n",
    "import pandas\n",
    "import caffe\n",
    "import numpy as np\n",
    "import ROOT\n",
    "import lmdb\n",
    "import time\n",
    "#imports the larcv tools from ROOT\n",
    "from larcv import larcv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The below instantiates the network based off the description in the prototxt and the saved pre-trained snapshot.\n",
    "\n",
    "> NOTE: The prototxt and cfg files will need to be adjusted to reflect the local file system.\n",
    "> Namely,  in `/workspace/plainresnet10b/sp_plainresnet10b_test.prototxt`, the following line should read:\n",
    "> ~~~\n",
    "> filler_config: \"/data/plainresnet10b/test_filler.cfg\"\n",
    "> ~~~\n",
    "> In addition, in `/workspace/plainresnet10b/test_filler.cfg`, the following line should now read: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<DataFillerProcessDriver::configure>\u001b[00m Instantiating Process ID=0 Type: ADCThreshold w/ Name: ADCThres\r\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<DataFillerProcessDriver::configure>\u001b[00m Instantiating Process ID=1 Type: SimpleFiller w/ Name: SimpleFiller\r\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<DataFillerIOManager::prepare_input>\u001b[00m Opening a file in READ mode: /workspace/test.root\r\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<DataFillerIOManager::initialize>\u001b[00m Prepared input with 42500 entries...\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\r\n",
      "E0209 21:46:46.730245  1638 common.cpp:113] Cannot create Cublas handle. Cublas won't be available.\r\n",
      "E0209 21:46:46.731740  1638 common.cpp:120] Cannot create Curand generator. Curand won't be available.\r\n"
     ]
    }
   ],
   "source": [
    "prototxt = '/workspace/plainresnet10b/sp_plainresnet10b_test.prototxt'\n",
    "model_snapshot = '/workspace/plainresnet10b/sp_plainresnet10b_iter_195750.caffemodel.h5'\n",
    "\n",
    "net = caffe.Net(prototxt, model_snapshot,caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we need to setup the IO so that we can access the data inline with caffe. This will allow us to compare prediction with output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<AnaIO::prepare_input>\u001b[00m Opening a file in READ mode: ../test.root\r\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<AnaIO::initialize>\u001b[00m Prepared input with 42500 entries...\r\n"
     ]
    }
   ],
   "source": [
    "filler_name = 'DataFiller'\n",
    "# check if larcv IO processor does in fact exist and registered in a factory\n",
    "if not larcv.ThreadFillerFactory.exist_filler(filler_name):\n",
    "    print '\\033[93mFiller',filler_name,'does not exist...\\033[00m'\n",
    "\n",
    "# get IO instance, ThreadDatumFiller instance, from the factory\n",
    "filler = larcv.ThreadFillerFactory.get_filler(filler_name)\n",
    "filler.pd().random_access(False)\n",
    "# get num events to be processed \n",
    "num_events = filler.get_n_entries()\n",
    "\n",
    "# construct our own IO to fetch ROI object for physics analysis, use RED mode w/ same input files\n",
    "myio = larcv.IOManager(0,\"AnaIO\")\n",
    "myio.add_in_file('../test.root')\n",
    "myio.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running Inference\n",
    "\n",
    "Here is the inference step. We're going to tell caffe to process the next batch of images. Then we're going to setup some variables to point at the relevant data.\n",
    "\n",
    "> WARNING WARNING WARNING: Failing to adjust the mini-batch size will cause this to fail. Open up:\n",
    "> `/workspace/plainresnet10b/sp_plainresnet10b_test.prototxt`\n",
    "> And change layer.root_data_param.batch_size to something small. The value, `1` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# force the filler to move the next event-to-read pointer to the entry of our interest\n",
    "filler.set_next_index(0)\n",
    "\n",
    "num_entries=10\n",
    "# This will take some time. Esp w/o a GPU\n",
    "net.forward()\n",
    "\n",
    "# Wait until the filler is done filling the buffer\n",
    "while filler.thread_running():\n",
    "    time.sleep(0.001)\n",
    "\n",
    "# get a vector of integers that record TTree entry numbers processed in this mini-batch\n",
    "entries = filler.processed_entries()\n",
    "\n",
    "# retrieve data already read-and-stored-in-memory from caffe blob\n",
    "adcimgs = net.blobs[\"data\"].data    # this is image\n",
    "labels  = net.blobs[\"label\"].data   # this is label\n",
    "scores  = net.blobs[\"softmax\"].data # this is final output softmax vector\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Processing the output\n",
    "\n",
    "For this next part, I'm not doing much in the way of processing. Usually, we'll save some results to CSV to compare later. For now, this just prints the information as it's coming out of the mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entry:  8898\n",
      "npx:  308\n",
      "Label:  1\n",
      "Prediction:  3\n",
      "EMinus:  0.151322\n",
      "Gamma:  0.253516\n",
      "MuMinus:  0.0832253\n",
      "PiMinus:  0.502918\n",
      "Proton:  0.00901945\n",
      "Energy Start:  659.822443128 :  654.115157533\n",
      "Momentum At Start:  (200.27086237530062, 386.0779576431554, 496.18650602415687)\n",
      "Decay?:  False\n"
     ]
    }
   ],
   "source": [
    "# loop over entry of mini-batch outcome\n",
    "for index in xrange(1):\n",
    "    print \"Entry: \", entries[index]\n",
    "    print \"npx: \", (adcimgs > 0).sum()\n",
    "    print \"Label: \", int(labels)\n",
    "    print \"Prediction: \", scores.argmax()\n",
    "    print \"EMinus: \", scores[index][0]\n",
    "    print \"Gamma: \", scores[index][1]\n",
    "    print \"MuMinus: \", scores[index][2]\n",
    "    print \"PiMinus: \", scores[index][3]\n",
    "    print \"Proton: \", scores[index][4]\n",
    "\n",
    "    if int(labels) == scores.argmax():\n",
    "        print \"FOUND CORRECT PARTICLE\"\n",
    "                \n",
    "    # now get ROI data from myroi, our separate IO handle, to record physics parameters\n",
    "    myio.read_entry(entries[index])\n",
    "    event_roi = myio.get_data(1,'tpc_hires_crop')\n",
    "                \n",
    "    # loop over ROIs\n",
    "    for roi in event_roi.ROIArray():\n",
    "        if roi.MCSTIndex() == larcv.kINVALID_USHORT:\n",
    "            print \"Energy Start: \", roi.EnergyInit(), \": \", roi.EnergyDeposit()\n",
    "            #print \"Mass: \", larcv.larcv.ParticleMass(roi.PdgCode())\n",
    "            print \"Momentum At Start: \", (roi.Px(),roi.Py(),roi.Pz())\n",
    "            print \"Decay?: \", (np.abs(roi.PdgCode()) == 13 and np.abs(roi.ParentPdgCode()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CLEANUP\n",
    "\n",
    "More important than anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "myio.finalize()\n",
    "# destroy thread filler via factory, an owner\n",
    "larcv.ThreadFillerFactory.destroy_filler(filler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
