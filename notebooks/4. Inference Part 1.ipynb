{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Single Inference\n",
    "\n",
    "> Warning: The major caveat here is that this really should be run via script and **NOT** in a notebook. That being said, this is the best way to introduce the concepts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require(['codemirror/mode/clike/clike'], function(Clike) { console.log('ROOTaaS - C++ CodeMirror module loaded'); });"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to ROOTaaS 6.06/08\n"
     ]
    }
   ],
   "source": [
    "import caffe\n",
    "from larcv import larcv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The below instantiates the network based off the description in the prototxt and the saved pre-trained snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prototxt = '/workspace/plainresnet10b/sp_plainresnet10b_test.prototxt'\n",
    "model_snapshot = '/workspace/plainresnet10b/sp_plainresnet10b_iter_195750.caffemodel.h5'\n",
    "net = caffe.Net(prototxt, model_snapshot,caffe.TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to setup the IO so that we can access the data inline with caffe. This will allow us to compare prediction with output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filler_name = 'DataFiller'\n",
    "# check if larcv IO processor does in fact exist and registered in a factory\n",
    "if not larcv.ThreadFillerFactory.exist_filler(filler_name):\n",
    "    print '\\033[93mFiller',filler_name,'does not exist...\\033[00m'\n",
    "\n",
    "# get IO instance, ThreadDatumFiller instance, from the factory\n",
    "filler = larcv.ThreadFillerFactory.get_filler(filler_name)\n",
    "\n",
    "# get # events to be processed \n",
    "num_events = filler.get_n_entries()\n",
    "# force random access to be false for an inference\n",
    "filler.set_random_access(False)\n",
    "\n",
    "# construct our own IO to fetch ROI object for physics analysis, use RED mode w/ same input files\n",
    "myio = larcv.IOManager(0,\"AnaIO\")\n",
    "for f in filler.pd().io().file_list():\n",
    "    myio.add_in_file(f)\n",
    "myio.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running Inference\n",
    "\n",
    "Here is the inference step. We're going to tell caffe to process the next batch of images, and we're going to setup some variables to point at the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# force the filler to move the next event-to-read pointer to the entry of our interest\n",
    "filler.set_next_index(event_counter)\n",
    "\n",
    "num_entries=10\n",
    "net.forward()\n",
    "\n",
    "while filler.thread_running():\n",
    "    time.sleep(0.001)\n",
    "\n",
    "roi_producer = filler.producer(1)\n",
    "\n",
    "# get a vector of integers that record TTree entry numbers processed in this mini-batch\n",
    "entries = filler.processed_entries()\n",
    "if entries.size() != self._batch_size:\n",
    "    print \"\\033[93mBatch counter mis-match!\\033[00m\"\n",
    "    raise Exception\n",
    "\n",
    "# retrieve data already read-and-stored-in-memory from caffe blob\n",
    "adcimgs = net.blobs[\"data\"].data    # this is image\n",
    "labels  = net.blobs[\"label\"].data   # this is label\n",
    "scores  = net.blobs[\"softmax\"].data # this is final output softmax vector\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the output\n",
    "\n",
    "For this next part, I'm not doing much in the way of processing. Usually, we'll save some results to CSV to compare later. For now, this is just print the information as it's coming out of the mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over entry of mini-batch outcome\n",
    "for index in xrange(num_entries):\n",
    "    print \"Entry: \", entries[index]\n",
    "    print \"npx: \", (adcimg > 0).sum()\n",
    "    print \"Label: \", int(label)\n",
    "    print \"Prediction: \", score.argmax()\n",
    "    print \"EMinus: \", score[0]\n",
    "    print \"Gamma: \", score[1]\n",
    "    print \"MuMinus: \", score[2]\n",
    "    print \"PiMinus: \", score[3]\n",
    "    print \"Proton: \", score[4]\n",
    "\n",
    "    if int(label) == score.argmax():\n",
    "        print \"FOUND CORRECT PARTICLE\"\n",
    "                \n",
    "    # now get ROI data from myroi, our separate IO handle, to record physics parameters\n",
    "    myio.read_entry(entries[index])\n",
    "    event_roi = myio.get_data(1,roi_producer)\n",
    "                \n",
    "    # loop over ROIs\n",
    "    for roi in event_roi.ROIArray():\n",
    "        if roi.MCSTIndex() == larcv.kINVALID_USHORT:\n",
    "            print \"Energy Start: \", roi.EnergyInit(), \": \", roi.EnergyDeposity\n",
    "            print \"Mass: \", larcv.ParticleMass(roi.PdgCode())\n",
    "            print \"Momentum At Start: \", (roi.Px(),roi.Py(),roi.Pz())\n",
    "            print \"Decay?: \", (np.abs(roi.PdgCode()) == 13 and np.abs(roi.ParentPdgCode()) == 211 or sv_vals['ndecay'] += 1\n",
    "                        elif np.abs(roi.PdgCode()) == 11 and np.abs(roi.ParentPdgCode()) == 13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANUP\n",
    "\n",
    "More important than anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myio.finalize()\n",
    "# destroy thread filler via factory, an owner\n",
    "larcv.ThreadFillerFactory.destroy_filler(filler_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
